{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment: analyzing movie reviews with Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "<img src=\"img/cinemaReviews.png\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "In this assignment we will analyze the sentiment, positive or negative, expressed in a set of movie reviews IMDB. To do so we will make use of word embeddings and recurrent neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "Throughout this notebook you will find empty cells that you will need to fill with your own code. Follow the instructions in the notebook and pay special attention to the following symbols.\n",
    "\n",
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>You will need to solve a question by writing your own code or answer in the cell immediately below, or in a different file as instructed.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>This is a hint or useful observation that can help you solve this assignment. You are not expected to write any solution, but you should pay attention to them to understand the assignment.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td>This is an advanced and voluntary exercise that can help you gain a deeper knowledge into the topic. Good luck!</td></tr>\n",
    "</table>\n",
    "\n",
    "During the assigment you will make use of several Python packages that might not be installed in your machine. If that is the case, you can install new Python packages with\n",
    "\n",
    "    conda install PACKAGENAME\n",
    "    \n",
    "if you are using Python Anaconda. Else you should use\n",
    "\n",
    "    pip install PACKAGENAME\n",
    "\n",
    "You will need the following packages for this particular assignment. Make sure they are available before proceeding:\n",
    "\n",
    "* **numpy**\n",
    "* **keras**\n",
    "* **matplotlib**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will embed any plots into the notebook instead of generating a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing required packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, if you need any help on the usage of a Python function you can place the writing cursor over its name and press Caps+Shift to produce a pop-out with related documentation. This will only work inside code cells. \n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Keras library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will make use of the <a href=http://keras.io/>keras</a> Deep Learning library for Python. This library allows building several kinds of shallow and deep networks, following either a sequential or a graph architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of a part of the IMDB database on movie reviews. IMDB rates movies with a score ranging 0-10, but for simplicity we will consider a dataset of good and bad reviews, where a review has been considered bad with a score smaller than 4, and good if it features a score larger than 7. The data is available under the *data* folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n",
    "Load the data into two variables, a list **text** with each of the movie reviews and a list **y** of the class labels.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB=pd.read_csv(\"C:\\\\Users\\\\raul_\\\\JupiterNotebooks\\\\MasterBigData\\\\data\\\\datafull.csv\",sep='\\t',header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords eliminated using NLTK\n",
    "stop = stopwords.words('english')\n",
    "IMDB['text']=IMDB['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I simply cant understand relics Ceausescu era ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Director Raoul Walsh like Michael Bay '40's ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>It could better film. It drag points, central ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>It hard rate film. As entertainment value 21st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I've read terrible things film, I prepared wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  I simply cant understand relics Ceausescu era ...\n",
       "1          1  Director Raoul Walsh like Michael Bay '40's ye...\n",
       "2          1  It could better film. It drag points, central ...\n",
       "3          1  It hard rate film. As entertainment value 21st...\n",
       "4          1  I've read terrible things film, I prepared wor..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(IMDB.shape)\n",
    "IMDB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=IMDB[\"text\"]\n",
    "y=IMDB[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we see,it's balanced the dataset\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience in what follows we will also split the data into a training and test subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n",
    "Split the list of texts into **texts_train** and **texts_test** lists, keeping 25% of the texts for test. Split in the same way the labels, obtaining lists **y_train** and **y_test**.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_IMDB = StratifiedShuffleSplit(n_splits=3, test_size=0.25, random_state=124)\n",
    "\n",
    "for train_index, test_index in split_IMDB.split(X, y):\n",
    "     \n",
    "       X_train, X_test = X[train_index], X[test_index]\n",
    "       y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12933    ...but working I surprised see many people con...\n",
      "8666     As rule, Full Moon production logo warning sig...\n",
      "21192    [***POSSIBLE SPOILERS***] This movie's reputat...\n",
      "20160    Even 1942 standards movie-making setup HER CAR...\n",
      "18376    I've never huge fan Mormon films. Being Mormon...\n",
      "Name: text, dtype: object\n",
      "12933    0\n",
      "8666     1\n",
      "21192    0\n",
      "20160    0\n",
      "18376    0\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't introduce text directly into the network, so we will have to tranform it to a vector representation. To do so, we will first **tokenize** the text into words (or tokens), and assign a unique identifier to each word found in the text. Doing this will allow us to perform the encoding. We can do this easily by making use of the **Tokenizer** class in keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Tokenizer offers convenient methods to split texts down to tokens. At construction time we need to supply the Tokenizer the maximum number of different words we are willing to represent. If out texts have greater word variety than this number, the least frequent words will be discarded. We will choose a number large enough for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxwords = 1000\n",
    "tokenizer = Tokenizer(num_words = maxwords, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to **fit** the Tokenizer to the training texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n",
    "Find in the keras documentation the appropriate Tokenizer method to fit the tokenizer on a list of text, then use it to fit it on the training data.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_train)\n",
    "tokenizer.fit_on_texts(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly, the following should show the number of times the tokenizer has found each word in the input texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('but', 8813),\n",
       "             ('working', 792),\n",
       "             ('i', 72637),\n",
       "             ('surprised', 802),\n",
       "             ('see', 11461),\n",
       "             ('many', 6672),\n",
       "             ('people', 9103),\n",
       "             ('consider', 512),\n",
       "             ('good', 15100),\n",
       "             ('on', 3422),\n",
       "             ('grounds', 62),\n",
       "             ('there', 6700),\n",
       "             ('loose', 277),\n",
       "             ('hints', 103),\n",
       "             ('whole', 3078),\n",
       "             ('material', 759),\n",
       "             ('self', 1184),\n",
       "             ('indulgent', 80),\n",
       "             ('unconvincing', 186),\n",
       "             (\"lynch's\", 46),\n",
       "             ('movies', 7649),\n",
       "             ('generally', 468),\n",
       "             ('intriguing', 301),\n",
       "             ('generate', 50),\n",
       "             ('sense', 2322),\n",
       "             ('confusion', 163),\n",
       "             ('yet', 2748),\n",
       "             ('playful', 40),\n",
       "             ('that', 5232),\n",
       "             ('visual', 522),\n",
       "             ('subplots', 87),\n",
       "             ('characters', 7055),\n",
       "             ('ideas', 593),\n",
       "             ('etc', 1212),\n",
       "             ('dull', 816),\n",
       "             ('yes', 1527),\n",
       "             ('pointless', 505),\n",
       "             ('because', 688),\n",
       "             ('whatever', 729),\n",
       "             ('explore', 118),\n",
       "             ('either', 1866),\n",
       "             ('small', 1641),\n",
       "             ('far', 2978),\n",
       "             ('fetched', 103),\n",
       "             ('simply', 1966),\n",
       "             ('told', 1063),\n",
       "             ('superior', 310),\n",
       "             ('manner', 409),\n",
       "             (\"it's\", 6427),\n",
       "             ('lynch', 232),\n",
       "             ('exploring', 66),\n",
       "             ('dv', 23),\n",
       "             ('nothing', 4272),\n",
       "             ('treated', 275),\n",
       "             ('like', 20272),\n",
       "             ('this', 18776),\n",
       "             ('1', 2201),\n",
       "             ('10', 4330),\n",
       "             ('as', 4418),\n",
       "             ('rule', 182),\n",
       "             ('full', 1772),\n",
       "             ('moon', 278),\n",
       "             ('production', 1785),\n",
       "             ('logo', 31),\n",
       "             ('warning', 315),\n",
       "             ('sign', 273),\n",
       "             ('avoid', 776),\n",
       "             ('film', 39098),\n",
       "             (\"i've\", 3342),\n",
       "             ('enjoyed', 1245),\n",
       "             ('jeffrey', 105),\n",
       "             ('combs', 45),\n",
       "             ('films', 6868),\n",
       "             ('gave', 1217),\n",
       "             ('shot', 2047),\n",
       "             ('br', 101871),\n",
       "             ('bad', 9270),\n",
       "             ('not', 4350),\n",
       "             ('great', 9045),\n",
       "             (\"that's\", 3410),\n",
       "             ('something', 5052),\n",
       "             ('else', 1935),\n",
       "             ('the', 49126),\n",
       "             ('involves', 224),\n",
       "             ('struggle', 327),\n",
       "             ('mystic', 26),\n",
       "             ('evil', 1432),\n",
       "             ('brother', 1033),\n",
       "             ('wants', 1287),\n",
       "             ('dominate', 43),\n",
       "             ('worlds', 141),\n",
       "             ('title', 1496),\n",
       "             ('character', 6704),\n",
       "             ('dr', 689),\n",
       "             ('mordrid', 25),\n",
       "             ('also', 9157),\n",
       "             ('deal', 717),\n",
       "             ('authorities', 65),\n",
       "             ('mundane', 85),\n",
       "             ('world', 3686),\n",
       "             ('successfully', 161),\n",
       "             ('possible', 1000),\n",
       "             ('spoilers', 582),\n",
       "             ('follow', 782),\n",
       "             ('travel', 246),\n",
       "             ('dimensions', 27),\n",
       "             ('find', 4127),\n",
       "             ('companion', 102),\n",
       "             ('guarding', 7),\n",
       "             ('fortress', 18),\n",
       "             ('however', 3537),\n",
       "             ('guard', 164),\n",
       "             ('blinded', 31),\n",
       "             ('his', 1680),\n",
       "             ('eyes', 1208),\n",
       "             ('ruined', 227),\n",
       "             ('pits', 28),\n",
       "             ('so', 4254),\n",
       "             ('wizard', 91),\n",
       "             ('passes', 106),\n",
       "             ('hands', 632),\n",
       "             ('across', 970),\n",
       "             (\"other's\", 76),\n",
       "             ('hey', 401),\n",
       "             ('presto', 7),\n",
       "             ('restored', 90),\n",
       "             ('sort', 1469),\n",
       "             ('healing', 36),\n",
       "             ('apparently', 917),\n",
       "             ('works', 1279),\n",
       "             ('later', 2193),\n",
       "             ('mordred', 1),\n",
       "             ('animate', 14),\n",
       "             ('couple', 1698),\n",
       "             ('animal', 333),\n",
       "             ('skeletons', 18),\n",
       "             ('museum', 93),\n",
       "             ('fight', 1139),\n",
       "             ('guess', 1311),\n",
       "             ('one', 26516),\n",
       "             ('wins', 163),\n",
       "             ('side', 1269),\n",
       "             ('picture', 1472),\n",
       "             ('though', 4565),\n",
       "             ('much', 9760),\n",
       "             ('comic', 897),\n",
       "             ('book', 2395),\n",
       "             (\"mordred's\", 1),\n",
       "             ('human', 1587),\n",
       "             ('adventures', 201),\n",
       "             ('okay', 713),\n",
       "             ('plays', 2211),\n",
       "             ('role', 3182),\n",
       "             ('convincingly', 93),\n",
       "             ('seen', 6678),\n",
       "             ('lots', 798),\n",
       "             ('worse', 1468),\n",
       "             (\"movie's\", 423),\n",
       "             ('reputation', 191),\n",
       "             ('precedes', 12),\n",
       "             ('it', 24634),\n",
       "             ('anticipation', 72),\n",
       "             ('sat', 289),\n",
       "             ('watch', 6971),\n",
       "             ('letterbox', 4),\n",
       "             ('tcm', 51),\n",
       "             ('what', 3666),\n",
       "             ('major', 926),\n",
       "             ('disappointment', 404),\n",
       "             ('cast', 3816),\n",
       "             ('superb', 671),\n",
       "             ('values', 465),\n",
       "             ('first', 9057),\n",
       "             ('rate', 626),\n",
       "             ('without', 3267),\n",
       "             ('depth', 510),\n",
       "             ('plot', 6551),\n",
       "             ('thin', 360),\n",
       "             ('thing', 4499),\n",
       "             ('goes', 2442),\n",
       "             ('long', 3442),\n",
       "             ('for', 3268),\n",
       "             ('movie', 43568),\n",
       "             ('deals', 257),\n",
       "             ('alcoholism', 37),\n",
       "             ('family', 3098),\n",
       "             ('divisions', 5),\n",
       "             ('unfaithfulness', 6),\n",
       "             ('gambling', 73),\n",
       "             ('sexual', 714),\n",
       "             ('repression', 21),\n",
       "             ('curiously', 49),\n",
       "             ('flat', 577),\n",
       "             ('prosaic', 11),\n",
       "             ('lifeless', 65),\n",
       "             ('cliche', 84),\n",
       "             ('ridden', 88),\n",
       "             ('example', 1374),\n",
       "             ('portrayal', 507),\n",
       "             ('frank', 450),\n",
       "             (\"hirsch's\", 1),\n",
       "             ('unfaithfuness', 1),\n",
       "             ('rather', 2734),\n",
       "             ('heavy', 487),\n",
       "             ('handed', 182),\n",
       "             ('request', 33),\n",
       "             ('wife', 2057),\n",
       "             ('go', 5147),\n",
       "             ('upstairs', 46),\n",
       "             ('relax', 78),\n",
       "             ('bit', 3053),\n",
       "             ('followed', 373),\n",
       "             ('predictable', 853),\n",
       "             ('pleading', 10),\n",
       "             ('headache', 61),\n",
       "             ('leads', 746),\n",
       "             ('even', 12652),\n",
       "             ('predictably', 55),\n",
       "             ('evening', 235),\n",
       "             ('liaison', 17),\n",
       "             ('secretary', 135),\n",
       "             ('nancy', 209),\n",
       "             ('got', 3585),\n",
       "             ('blues', 99),\n",
       "             ('tonight', 94),\n",
       "             (\"let's\", 667),\n",
       "             ('drive', 445),\n",
       "             ('according', 296),\n",
       "             ('well', 10655),\n",
       "             ('worn', 88),\n",
       "             ('formula', 252),\n",
       "             ('we', 2060),\n",
       "             ('feel', 2943),\n",
       "             ('real', 4717),\n",
       "             ('cardboard', 131),\n",
       "             ('cutouts', 15),\n",
       "             ('acting', 6479),\n",
       "             ('marionette', 2),\n",
       "             ('play', 2226),\n",
       "             ('source', 206),\n",
       "             ('obvious', 1066),\n",
       "             ('friction', 15),\n",
       "             ('dave', 115),\n",
       "             ('hirsch', 15),\n",
       "             ('never', 6480),\n",
       "             ('really', 11736),\n",
       "             ('explored', 106),\n",
       "             ('explained', 284),\n",
       "             (\"dave's\", 2),\n",
       "             ('infatuation', 14),\n",
       "             ('again', 2290),\n",
       "             ('off', 1521),\n",
       "             ('gwen', 12),\n",
       "             ('inexplicable', 68),\n",
       "             ('light', 970),\n",
       "             ('fatuous', 6),\n",
       "             ('inability', 79),\n",
       "             ('defecate', 1),\n",
       "             ('get', 9270),\n",
       "             ('pot', 98),\n",
       "             ('subsequent', 121),\n",
       "             ('marriage', 416),\n",
       "             ('desperation', 104),\n",
       "             ('shirley', 97),\n",
       "             ('maclaine', 19),\n",
       "             ('ginny', 4),\n",
       "             ('is', 4085),\n",
       "             ('moment', 1104),\n",
       "             ('presented', 415),\n",
       "             ('viewer', 1195),\n",
       "             ('anyway', 1117),\n",
       "             ('obviously', 1163),\n",
       "             ('doomed', 104),\n",
       "             ('fail', 284),\n",
       "             ('clear', 786),\n",
       "             ('conventions', 72),\n",
       "             ('type', 1121),\n",
       "             ('soap', 285),\n",
       "             ('opera', 393),\n",
       "             ('could', 7747),\n",
       "             ('resolved', 60),\n",
       "             ('someone', 2241),\n",
       "             ('killed', 1111),\n",
       "             ('jealous', 121),\n",
       "             ('lover', 379),\n",
       "             ('started', 963),\n",
       "             ('running', 992),\n",
       "             ('around', 3615),\n",
       "             ('gun', 554),\n",
       "             ('bet', 242),\n",
       "             ('would', 12238),\n",
       "             ('phony', 83),\n",
       "             ('capital', 87),\n",
       "             (\"'p'\", 2),\n",
       "             ('having', 384),\n",
       "             ('said', 2196),\n",
       "             (\"maclaine's\", 3),\n",
       "             ('performance', 2897),\n",
       "             ('dean', 184),\n",
       "             ('martin', 342),\n",
       "             ('standouts', 15),\n",
       "             ('here', 2783),\n",
       "             ('interest', 1029),\n",
       "             ('purely', 169),\n",
       "             ('period', 766),\n",
       "             ('piece', 1533),\n",
       "             ('hollywood', 1796),\n",
       "             ('history', 1323),\n",
       "             ('1942', 40),\n",
       "             ('standards', 354),\n",
       "             ('making', 2951),\n",
       "             ('setup', 64),\n",
       "             ('her', 2579),\n",
       "             ('presents', 207),\n",
       "             ('dated', 266),\n",
       "             ('extreme', 349),\n",
       "             ('machinations', 24),\n",
       "             ('half', 2092),\n",
       "             ('pair', 238),\n",
       "             ('of', 2878),\n",
       "             ('husband', 949),\n",
       "             ('ex', 465),\n",
       "             ('back', 4959),\n",
       "             ('threat', 115),\n",
       "             ('another', 4320),\n",
       "             ('divorce', 101),\n",
       "             ('eventual', 59),\n",
       "             ('separation', 30),\n",
       "             ('means', 761),\n",
       "             ('jealousy', 57),\n",
       "             ('humiliation', 29),\n",
       "             ('schemes', 32),\n",
       "             ('done', 3095),\n",
       "             ('better', 5739),\n",
       "             ('classics', 229),\n",
       "             ('girl', 2722),\n",
       "             ('friday', 193),\n",
       "             ('philadelphia', 34),\n",
       "             ('story', 11896),\n",
       "             ('both', 595),\n",
       "             ('features', 640),\n",
       "             ('women', 1731),\n",
       "             ('strong', 1097),\n",
       "             ('indomitable', 4),\n",
       "             ('screen', 2479),\n",
       "             ('presence', 410),\n",
       "             ('played', 2588),\n",
       "             ('independent', 312),\n",
       "             ('proto', 10),\n",
       "             ('feminist', 83),\n",
       "             ('in', 8358),\n",
       "             ('estranged', 59),\n",
       "             ('divorced', 60),\n",
       "             ('witty', 273),\n",
       "             ('husbands', 76),\n",
       "             ('set', 2445),\n",
       "             ('marry', 225),\n",
       "             ('colorless', 11),\n",
       "             ('men', 1843),\n",
       "             ('exact', 189),\n",
       "             ('opposite', 266),\n",
       "             ('bamboozled', 6),\n",
       "             ('rejecting', 12),\n",
       "             ('soon', 1223),\n",
       "             ('to', 3141),\n",
       "             ('be', 1437),\n",
       "             ('re', 747),\n",
       "             ('igniting', 5),\n",
       "             ('passion', 295),\n",
       "             ('other', 1163),\n",
       "             ('switches', 38),\n",
       "             ('gender', 90),\n",
       "             ('norma', 32),\n",
       "             ('shearer', 25),\n",
       "             ('cary', 106),\n",
       "             ('grant', 246),\n",
       "             ('out', 2725),\n",
       "             ('time', 12684),\n",
       "             ('ward', 121),\n",
       "             ('boyfriend', 390),\n",
       "             ('george', 840),\n",
       "             ('sanders', 52),\n",
       "             ('hiring', 32),\n",
       "             ('robert', 939),\n",
       "             ('taylor', 285),\n",
       "             ('pose', 47),\n",
       "             ('gigolo', 21),\n",
       "             ('problem', 1447),\n",
       "             ('old', 4498),\n",
       "             ('playing', 1631),\n",
       "             ('suited', 111),\n",
       "             ('actress', 1209),\n",
       "             ('mid', 318),\n",
       "             ('late', 1210),\n",
       "             ('twenties', 29),\n",
       "             ('involved', 1076),\n",
       "             ('furniture', 55),\n",
       "             ('man', 5569),\n",
       "             ('love', 6392),\n",
       "             ('fiancée', 43),\n",
       "             ('seeing', 2098),\n",
       "             ('strange', 926),\n",
       "             ('come', 3185),\n",
       "             ('bathroom', 114),\n",
       "             ('happens', 1080),\n",
       "             ('knock', 139),\n",
       "             ('lights', 181),\n",
       "             ('cause', 479),\n",
       "             ('huge', 944),\n",
       "             ('scene', 5349),\n",
       "             ('and', 11449),\n",
       "             ('part', 4027),\n",
       "             ('trying', 2469),\n",
       "             ('channel', 431),\n",
       "             ('speech', 200),\n",
       "             ('inflections', 10),\n",
       "             ('overall', 1437),\n",
       "             ('essence', 138),\n",
       "             ('worst', 2727),\n",
       "             ('herself', 221),\n",
       "             ('used', 1879),\n",
       "             ('parts', 1191),\n",
       "             ('intellectual', 175),\n",
       "             ('sexiness', 8),\n",
       "             ('dramatic', 666),\n",
       "             ('consuelo', 3),\n",
       "             ('craydon', 1),\n",
       "             ('seems', 3619),\n",
       "             ('put', 2379),\n",
       "             ('throes', 10),\n",
       "             ('complete', 1032),\n",
       "             ('over', 1454),\n",
       "             ('emoting', 19),\n",
       "             ('gesturing', 3),\n",
       "             ('which', 1387),\n",
       "             ('still', 5619),\n",
       "             ('style', 1593),\n",
       "             ('appropriate', 221),\n",
       "             ('ten', 828),\n",
       "             ('years', 4503),\n",
       "             ('earlier', 663),\n",
       "             ('makes', 4201),\n",
       "             ('look', 4139),\n",
       "             ('extremely', 1069),\n",
       "             ('mannered', 47),\n",
       "             ('performer', 101),\n",
       "             ('wrenching', 62),\n",
       "             ('joke', 620),\n",
       "             ('situation', 666),\n",
       "             ('water', 533),\n",
       "             ('fairly', 587),\n",
       "             ('dry', 229),\n",
       "             ('sponge', 13),\n",
       "             ('fuels', 11),\n",
       "             ('fires', 44),\n",
       "             ('tell', 1714),\n",
       "             ('theory', 189),\n",
       "             ('gives', 1577),\n",
       "             ('irving', 40),\n",
       "             ('thalberg', 6),\n",
       "             ('maker', 157),\n",
       "             ('career', 1004),\n",
       "             ('chooser', 1),\n",
       "             ('most', 925),\n",
       "             ('roles', 1112),\n",
       "             ('passed', 246),\n",
       "             ('charlotte', 93),\n",
       "             ('vale', 3),\n",
       "             ('mrs', 259),\n",
       "             ('miniver', 3),\n",
       "             ('mega', 42),\n",
       "             ('hits', 271),\n",
       "             ('now', 2242),\n",
       "             ('voyager', 43),\n",
       "             ('mystery', 844),\n",
       "             ('accounts', 57),\n",
       "             ('state', 524),\n",
       "             ('burnt', 49),\n",
       "             (\"she'd\", 58),\n",
       "             ('lost', 1537),\n",
       "             ('altogether', 112),\n",
       "             ('secret', 601),\n",
       "             ('anyone', 2572),\n",
       "             ('experienced', 191),\n",
       "             ('essentially', 257),\n",
       "             ('focus', 505),\n",
       "             (\"can't\", 3531),\n",
       "             ('wait', 717),\n",
       "             ('retirement', 40),\n",
       "             ('end', 5643),\n",
       "             ('contract', 129),\n",
       "             ('near', 822),\n",
       "             ('leave', 1099),\n",
       "             ('such', 466),\n",
       "             ('case', 1527),\n",
       "             ('she', 2725),\n",
       "             ('tired', 380),\n",
       "             ('ill', 291),\n",
       "             ('ease', 110),\n",
       "             ('going', 4094),\n",
       "             ('autopilot', 9),\n",
       "             ('instead', 2191),\n",
       "             ('living', 1061),\n",
       "             ('after', 1880),\n",
       "             ('make', 8014),\n",
       "             ('more', 1298),\n",
       "             ('responsible', 276),\n",
       "             ('discovering', 75),\n",
       "             ('janet', 46),\n",
       "             ('leigh', 66),\n",
       "             ('star', 2051),\n",
       "             ('40s', 57),\n",
       "             ('60s', 136),\n",
       "             ('fan', 1901),\n",
       "             ('mormon', 54),\n",
       "             ('being', 402),\n",
       "             ('always', 3237),\n",
       "             ('felt', 1527),\n",
       "             ('humor', 1305),\n",
       "             ('exclusive', 27),\n",
       "             ('lds', 37),\n",
       "             ('community', 289),\n",
       "             ('made', 8356),\n",
       "             ('us', 3786),\n",
       "             ('seem', 2174),\n",
       "             ('bunch', 810),\n",
       "             ('obsessive', 56),\n",
       "             ('wackos', 4),\n",
       "             ('hoping', 406),\n",
       "             ('breath', 177),\n",
       "             ('fresh', 374),\n",
       "             ('air', 639),\n",
       "             ('halestorm', 8),\n",
       "             ('finally', 1536),\n",
       "             ('discuss', 106),\n",
       "             ('non', 898),\n",
       "             ('friends', 1772),\n",
       "             ('boy', 1476),\n",
       "             ('wrong', 1817),\n",
       "             ('figured', 187),\n",
       "             ('since', 2906),\n",
       "             ('b', 1257),\n",
       "             ('list', 582),\n",
       "             ('talent', 929),\n",
       "             ('clint', 108),\n",
       "             ('howard', 230),\n",
       "             ('gary', 261),\n",
       "             ('coleman', 33),\n",
       "             ('andrew', 140),\n",
       "             ('wilson', 188),\n",
       "             ('fred', 295),\n",
       "             ('willard', 25),\n",
       "             ('favorites', 187),\n",
       "             ('least', 3113),\n",
       "             ('little', 6426),\n",
       "             ('funny', 4276),\n",
       "             ('besides', 410),\n",
       "             ('church', 395),\n",
       "             ('basketball', 88),\n",
       "             ('ripe', 24),\n",
       "             ('potential', 612),\n",
       "             ('plenty', 631),\n",
       "             ('hilarious', 968),\n",
       "             ('gags', 262),\n",
       "             ('must', 3198),\n",
       "             ('say', 5391),\n",
       "             ('throughout', 1361),\n",
       "             ('entire', 1461),\n",
       "             ('seemed', 1363),\n",
       "             ('knew', 898),\n",
       "             ('doing', 190),\n",
       "             ('every', 3975),\n",
       "             ('fell', 346),\n",
       "             ('opportunity', 389),\n",
       "             ('genuinely', 251),\n",
       "             ('gag', 139),\n",
       "             ('went', 1462),\n",
       "             ('ignored', 120),\n",
       "             ('dialogue', 1541),\n",
       "             ('bland', 274),\n",
       "             ('development', 641),\n",
       "             ('ever', 5987),\n",
       "             ('single', 916),\n",
       "             (\"wilson's\", 12),\n",
       "             ('less', 1998),\n",
       "             ('dimensional', 255),\n",
       "             ('hard', 2665),\n",
       "             ('believe', 2504),\n",
       "             ('nine', 157),\n",
       "             ('writes', 94),\n",
       "             ('mind', 1972),\n",
       "             ('numbingly', 36),\n",
       "             ('stale', 87),\n",
       "             ('train', 409),\n",
       "             ('wreck', 127),\n",
       "             ('witnessed', 88),\n",
       "             ('words', 882),\n",
       "             ('rage', 109),\n",
       "             ('sitting', 450),\n",
       "             ('my', 2326),\n",
       "             ('extras', 227),\n",
       "             ('final', 1324),\n",
       "             ('game', 1262),\n",
       "             ('premiere', 78),\n",
       "             ('washington', 250),\n",
       "             ('city', 1156),\n",
       "             ('ut', 2),\n",
       "             ('kurt', 144),\n",
       "             ('hale', 38),\n",
       "             ('director', 4184),\n",
       "             ('avoided', 102),\n",
       "             ('contact', 148),\n",
       "             ('show', 6167),\n",
       "             ('he', 5278),\n",
       "             ('waited', 95),\n",
       "             ('door', 428),\n",
       "             ('seemingly', 348),\n",
       "             ('ready', 334),\n",
       "             ('feedback', 10),\n",
       "             ('bring', 867),\n",
       "             ('ripped', 138),\n",
       "             ('away', 2765),\n",
       "             ('hour', 1183),\n",
       "             ('life', 6557),\n",
       "             ('left', 2123),\n",
       "             ('nasty', 339),\n",
       "             ('painful', 415),\n",
       "             ('scar', 19),\n",
       "             ('forget', 717),\n",
       "             ('specific', 135),\n",
       "             ('problems', 887),\n",
       "             ('had', 412),\n",
       "             ('minor', 400),\n",
       "             ('subplot', 121),\n",
       "             ('janitor', 35),\n",
       "             ('chubby', 26),\n",
       "             ('piano', 122),\n",
       "             ('player', 295),\n",
       "             ('two', 6889),\n",
       "             ('came', 1671),\n",
       "             ('nowhere', 442),\n",
       "             ('impossible', 494),\n",
       "             ('care', 1381),\n",
       "             ('about', 1085),\n",
       "             ('constantly', 416),\n",
       "             ('wondering', 359),\n",
       "             ('supposed', 1515),\n",
       "             ('lame', 741),\n",
       "             ('uninteresting', 199),\n",
       "             ('popped', 48),\n",
       "             ('then', 2143),\n",
       "             ('promising', 207),\n",
       "             ('audience', 2145),\n",
       "             ('chance', 1065),\n",
       "             ('laughs', 658),\n",
       "             ('puff', 10),\n",
       "             ('smoke', 118),\n",
       "             ('ending', 2352),\n",
       "             ('start', 1697),\n",
       "             ('caring', 165),\n",
       "             ('pretty', 3661),\n",
       "             ('letdown', 43),\n",
       "             ('everyone', 2125),\n",
       "             (\"who's\", 707),\n",
       "             ('expecting', 588),\n",
       "             ('true', 2322),\n",
       "             ('jokes', 970),\n",
       "             ('mormons', 29),\n",
       "             ('loud', 436),\n",
       "             ('ringing', 28),\n",
       "             ('sensation', 38),\n",
       "             ('ears', 98),\n",
       "             ('please', 1047),\n",
       "             ('keep', 1597),\n",
       "             ('fantasy', 644),\n",
       "             ('spare', 107),\n",
       "             ('oh', 1425),\n",
       "             ('dear', 143),\n",
       "             ('oireland', 1),\n",
       "             ('religion', 234),\n",
       "             ('no', 2631),\n",
       "             ('doubt', 754),\n",
       "             (\"we'll\", 113),\n",
       "             ('depressing', 225),\n",
       "             ('nonsense', 287),\n",
       "             ('featuring', 277),\n",
       "             ('hunky', 39),\n",
       "             ('macho', 70),\n",
       "             ('freedom', 235),\n",
       "             ('fighters', 39),\n",
       "             ('ira', 53),\n",
       "             ('initial', 209),\n",
       "             ('reaction', 248),\n",
       "             ('credits', 671),\n",
       "             ('shock', 377),\n",
       "             ('starts', 1220),\n",
       "             ('day', 2698),\n",
       "             ('wedding', 304),\n",
       "             ('sean', 254),\n",
       "             ('cloney', 3),\n",
       "             ('sheila', 31),\n",
       "             ('kelly', 373),\n",
       "             ('1950s', 154),\n",
       "             ('slight', 135),\n",
       "             (\"they're\", 1249),\n",
       "             ('getting', 1624),\n",
       "             ('married', 585),\n",
       "             ('catholic', 152),\n",
       "             ('protestant', 14),\n",
       "             ('order', 946),\n",
       "             ('happen', 1041),\n",
       "             ('takes', 2192),\n",
       "             ('pledge', 10),\n",
       "             ('children', 1331),\n",
       "             ('brought', 737),\n",
       "             ('attend', 83),\n",
       "             ('school', 1632),\n",
       "             ('enough', 3450),\n",
       "             ('jumps', 160),\n",
       "             ('forward', 651),\n",
       "             ('daughters', 170),\n",
       "             ('decided', 705),\n",
       "             (\"they'll\", 121),\n",
       "             ('attending', 53),\n",
       "             ('local', 876),\n",
       "             ('disgust', 62),\n",
       "             ('priest', 219),\n",
       "             ('father', 1933),\n",
       "             ('stafford', 5),\n",
       "             ('from', 1255),\n",
       "             ('things', 3680),\n",
       "             ('escalate', 6),\n",
       "             ('let', 1665),\n",
       "             ('cards', 99),\n",
       "             ('table', 180),\n",
       "             ('despite', 1365),\n",
       "             ('irish', 195),\n",
       "             ('scottish', 93),\n",
       "             ('heritage', 29),\n",
       "             ('agnostic', 9),\n",
       "             ('considered', 484),\n",
       "             ('atheist', 21),\n",
       "             ('adult', 501),\n",
       "             ('fact', 3523),\n",
       "             ('comes', 2484),\n",
       "             ('marxist', 20),\n",
       "             ('cynical', 154),\n",
       "             ('weapon', 145),\n",
       "             ('manipulate', 37),\n",
       "             ('a', 7948),\n",
       "             ('divided', 47),\n",
       "             ('shows', 2305),\n",
       "             ('appointed', 24),\n",
       "             ('moral', 363),\n",
       "             ('guardians', 9),\n",
       "             ('take', 3505),\n",
       "             ('upon', 859),\n",
       "             ('think', 7297),\n",
       "             ('may', 3364),\n",
       "             ('temerity', 5),\n",
       "             ('karl', 77),\n",
       "             ('marx', 35),\n",
       "             ('saw', 3166),\n",
       "             (\"he'd\", 180),\n",
       "             ('call', 919),\n",
       "             ('masterpiece', 608),\n",
       "             ('perhaps', 1684),\n",
       "             ('drama', 1402),\n",
       "             ('thinking', 1177),\n",
       "             ('reply', 26),\n",
       "             ('reviewers', 262),\n",
       "             ('claimed', 100),\n",
       "             ('propaganda', 203),\n",
       "             ('claim', 222),\n",
       "             ('know', 6157),\n",
       "             ('details', 410),\n",
       "             ('happened', 1076),\n",
       "             ('county', 49),\n",
       "             ('wexford', 2),\n",
       "             (\"there's\", 3084),\n",
       "             ('denying', 38),\n",
       "             ('flock', 53),\n",
       "             ('sheep', 43),\n",
       "             ('portrayed', 601),\n",
       "             ('guys', 1287),\n",
       "             ('blameless', 3),\n",
       "             ('woman', 2646),\n",
       "             ('rural', 110),\n",
       "             ('village', 253),\n",
       "             ('ireland', 110),\n",
       "             ('catholics', 16),\n",
       "             ('changes', 386),\n",
       "             ('believes', 228),\n",
       "             ('consequences', 123),\n",
       "             ('taking', 953),\n",
       "             ('pledges', 3),\n",
       "             ('keeping', 276),\n",
       "             ('disappears', 72),\n",
       "             ('pick', 451),\n",
       "             ('pieces', 423),\n",
       "             ('shattered', 28),\n",
       "             ('lives', 1386),\n",
       "             ('picked', 330),\n",
       "             ('former', 509),\n",
       "             ('andy', 295),\n",
       "             ('bailey', 24),\n",
       "             ('shown', 994),\n",
       "             ('gallant', 4),\n",
       "             ('member', 322),\n",
       "             ('change', 959),\n",
       "             (\"we're\", 526),\n",
       "             ('talking', 945),\n",
       "             (\"devil's\", 60),\n",
       "             ('own', 434),\n",
       "             ('lot', 3966),\n",
       "             ('agree', 572),\n",
       "             ('if', 5896),\n",
       "             ('criticism', 173),\n",
       "             ('feels', 809),\n",
       "             ('tvm', 11),\n",
       "             ('cinematic', 412),\n",
       "             ('live', 1544),\n",
       "             ('essential', 162),\n",
       "             ('viewing', 750),\n",
       "             ('thinks', 437),\n",
       "             ('opium', 7),\n",
       "             ('masses', 81),\n",
       "             ('sure', 2686),\n",
       "             ('oldboy', 3),\n",
       "             ('days', 1256),\n",
       "             ('amazingly', 174),\n",
       "             ('shocking', 334),\n",
       "             ('high', 2143),\n",
       "             ('budget', 1830),\n",
       "             ('hyped', 72),\n",
       "             ('way', 8020),\n",
       "             ('spin', 152),\n",
       "             ('kick', 265),\n",
       "             ('comedy', 3220),\n",
       "             ('group', 1025),\n",
       "             ('decide', 482),\n",
       "             ('pour', 35),\n",
       "             ('hearts', 135),\n",
       "             ('tae', 3),\n",
       "             ('kwon', 6),\n",
       "             ('do', 1754),\n",
       "             ('regardless', 125),\n",
       "             ('expect', 1177),\n",
       "             ('guaranteed', 72),\n",
       "             ('moved', 322),\n",
       "             ('work', 4371),\n",
       "             ('pain', 379),\n",
       "             ('expectations', 401),\n",
       "             ('force', 506),\n",
       "             ('experience', 1057),\n",
       "             ('comedic', 314),\n",
       "             ('times', 3233),\n",
       "             ('moments', 1662),\n",
       "             ('rendered', 68),\n",
       "             ('beautifully', 436),\n",
       "             ('seriously', 1002),\n",
       "             ('hoodlum', 12),\n",
       "             ('turned', 925),\n",
       "             ('guy', 2944),\n",
       "             ('second', 1958),\n",
       "             ('meek', 42),\n",
       "             ('team', 804),\n",
       "             ('substitute', 46),\n",
       "             ('die', 788),\n",
       "             ('happy', 957),\n",
       "             ('rounded', 69),\n",
       "             ('importantly', 127),\n",
       "             ('hopes', 273),\n",
       "             ('dreams', 432),\n",
       "             ('while', 1769),\n",
       "             ('goals', 56),\n",
       "             ('simple', 1021),\n",
       "             ('aspects', 398),\n",
       "             ('merely', 359),\n",
       "             ('highlight', 202),\n",
       "             ('overcome', 153),\n",
       "             ('personal', 628),\n",
       "             ('inter', 46),\n",
       "             ('struggles', 155),\n",
       "             ('short', 1862),\n",
       "             ('feeling', 1142),\n",
       "             ('determined', 164),\n",
       "             ('satisfied', 106),\n",
       "             ('amazing', 1319),\n",
       "             ('you', 4760),\n",
       "             ('truly', 1743),\n",
       "             ('lived', 382),\n",
       "             ('tragic', 347),\n",
       "             ('events', 910),\n",
       "             ('cry', 395),\n",
       "             ('along', 1775),\n",
       "             ('passionate', 97),\n",
       "             ('himself', 638),\n",
       "             ('ensure', 57),\n",
       "             ('others', 1578),\n",
       "             ('survive', 260),\n",
       "             ('wretched', 79),\n",
       "             ('video', 1718),\n",
       "             ('down', 880),\n",
       "             ('manages', 582),\n",
       "             ('brighter', 21),\n",
       "             ('jonny', 21),\n",
       "             ('did', 1063),\n",
       "             ('unbearable', 116),\n",
       "             ('regret', 189),\n",
       "             ('knowing', 446),\n",
       "             ('sooner', 72),\n",
       "             ('visited', 75),\n",
       "             ('england', 289),\n",
       "             ('2', 2858),\n",
       "             ('able', 1258),\n",
       "             (\"i'd\", 1346),\n",
       "             ('met', 287),\n",
       "             ('him', 2520),\n",
       "             ('comforting', 21),\n",
       "             ('cloud', 33),\n",
       "             ('free', 695),\n",
       "             ('rest', 1802),\n",
       "             ('peace', 202),\n",
       "             ('deserve', 287),\n",
       "             ('given', 1848),\n",
       "             ('stardust', 50),\n",
       "             ('course', 2505),\n",
       "             ('magically', 46),\n",
       "             ('fairy', 204),\n",
       "             ('tale', 786),\n",
       "             ('princess', 194),\n",
       "             ('bride', 131),\n",
       "             ('definitely', 1580),\n",
       "             ('wonderful', 1655),\n",
       "             ('spectacle', 58),\n",
       "             (\"2000's\", 12),\n",
       "             (\"1990's\", 42),\n",
       "             ('exciting', 515),\n",
       "             ('equipped', 17),\n",
       "             ('imagery', 183),\n",
       "             ('unforgettable', 144),\n",
       "             ('michelle', 169),\n",
       "             ('pfeiffer', 53),\n",
       "             (\"deniro's\", 8),\n",
       "             ('especially', 2536),\n",
       "             ('challenge', 164),\n",
       "             ('smile', 289),\n",
       "             ('minutes', 2944),\n",
       "             ('perfectly', 637),\n",
       "             ('journey', 428),\n",
       "             ('destination', 49),\n",
       "             ('enthralls', 1),\n",
       "             ('finish', 411),\n",
       "             ('stars', 1684),\n",
       "             ('decimal', 4),\n",
       "             ('cinematographical', 2),\n",
       "             ('buffs', 98),\n",
       "             ('rank', 102),\n",
       "             ('anything', 2944),\n",
       "             ('profound', 138),\n",
       "             ('truth', 692),\n",
       "             ('intentions', 159),\n",
       "             ('series', 3389),\n",
       "             ('understand', 1644),\n",
       "             ('p', 326),\n",
       "             ('o', 300),\n",
       "             ('v', 266),\n",
       "             ('granted', 201),\n",
       "             ('specifics', 14),\n",
       "             ('renderings', 4),\n",
       "             ('writer', 1098),\n",
       "             ('cannot', 1097),\n",
       "             ('expected', 704),\n",
       "             ('biblically', 4),\n",
       "             ('accurate', 283),\n",
       "             ('justifiably', 17),\n",
       "             ('scares', 188),\n",
       "             ('viewers', 776),\n",
       "             (\"i'm\", 4736),\n",
       "             ('christian', 370),\n",
       "             ('due', 909),\n",
       "             ('decision', 239),\n",
       "             ('accept', 300),\n",
       "             ('jesus', 267),\n",
       "             ('savior', 28),\n",
       "             ('similar', 852),\n",
       "             ('circumstances', 218),\n",
       "             ('therein', 30),\n",
       "             ('remarkably', 105),\n",
       "             ('scare', 217),\n",
       "             ('actions', 311),\n",
       "             ('decisions', 104),\n",
       "             ('cheap', 890),\n",
       "             ('attempt', 1049),\n",
       "             ('believing', 136),\n",
       "             ('god', 1110),\n",
       "             ('attention', 906),\n",
       "             (\"i'll\", 973),\n",
       "             ('behind', 1278),\n",
       "             ...])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have trained the tokenizer we can use it to vectorize the texts. In particular, we would like to transform the texts to sequences of word indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n",
    "Find in the keras documentation the appropriate Tokenizer method to transform a list of texts to a sequence. Apply it to both the training and test data to obtain matrices **X_train** and **X_test**.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=tokenizer.texts_to_sequences(X_train)    #####  Texts -> sequences fo integers\n",
    "X_test=tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now how a text has been transformed to a list of word indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26,\n",
       " 723,\n",
       " 2,\n",
       " 714,\n",
       " 16,\n",
       " 42,\n",
       " 23,\n",
       " 10,\n",
       " 117,\n",
       " 40,\n",
       " 40,\n",
       " 146,\n",
       " 761,\n",
       " 470,\n",
       " 33,\n",
       " 208,\n",
       " 167,\n",
       " 63,\n",
       " 40,\n",
       " 208,\n",
       " 35,\n",
       " 957,\n",
       " 460,\n",
       " 26,\n",
       " 697,\n",
       " 354,\n",
       " 828,\n",
       " 788,\n",
       " 276,\n",
       " 327,\n",
       " 276,\n",
       " 150,\n",
       " 261,\n",
       " 520,\n",
       " 47,\n",
       " 84,\n",
       " 8,\n",
       " 9,\n",
       " 229,\n",
       " 80]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is enough to train a Sequential Network. However, for efficiency reasons it is recommended that all sequences in the data have the same number of elements. Since this is not the case for our data, should **pad** the sequences to ensure the same length. The padding procedure adds a special *null* symbol to short sequences, and clips out parts of long sequences, thus enforcing a common size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n",
    "Find in the keras documentation the appropriate text preprocessing method to pad a sequence. Then pad all sequences to have a maximum of 300 words, both in the training and test data.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=300)  ###padding/truncating\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=300)    ### 300 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM network with Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform the word indices into something more amenable for a network we will use an <a href=https://keras.io/layers/embeddings/>**Embedding**</a> layer at the very beginning of the network. This layer will transform word indexes to a vector representation that is learned with the model together with the rest of network weights. After this transformation we will make use of an <a href=https://keras.io/layers/recurrent/#lstm>**LSTM**</a> layer to analyze the whole sequence, and then a final layer taking the decision of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n",
    "Build, compile and train a keras network with the following structure:\n",
    "<ul>\n",
    " <li>Embedding layer producing a vector representation of 64 elements</li>\n",
    " <li>LSTM layer of 32 units</li>\n",
    " <li>Dropout of 0.9</li>\n",
    " <li>Dense layer of 1 unit with sigmoid activation</li>\n",
    "</ul>\n",
    "Note that the Embedding layer requires specifing as first argument the maximum number of words we chose to for the tokenizer. Also, the LSTM layer requires setting the **input_length** parameter as the number of elements in the input sequences. \n",
    "Use the binary crossentropy loss function for training, together with the adam optimizer. Train for 10 epochs. After training, measure the accuracy on the test set.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88073"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len(tokenizer.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, LSTM, GlobalMaxPool1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1, 64,input_length=300))\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18750 samples, validate on 6250 samples\n",
      "Epoch 1/10\n",
      " - 53s - loss: 0.5806 - acc: 0.7078 - val_loss: 0.3823 - val_acc: 0.8440\n",
      "Epoch 2/10\n",
      " - 51s - loss: 0.3535 - acc: 0.8546 - val_loss: 0.3348 - val_acc: 0.8622\n",
      "Epoch 3/10\n",
      " - 50s - loss: 0.3174 - acc: 0.8726 - val_loss: 0.3397 - val_acc: 0.8579\n",
      "Epoch 4/10\n",
      " - 52s - loss: 0.3029 - acc: 0.8780 - val_loss: 0.3297 - val_acc: 0.8590\n",
      "Epoch 5/10\n",
      " - 52s - loss: 0.2938 - acc: 0.8822 - val_loss: 0.3472 - val_acc: 0.8581\n",
      "Epoch 6/10\n",
      " - 50s - loss: 0.2828 - acc: 0.8881 - val_loss: 0.3343 - val_acc: 0.8558\n",
      "Epoch 7/10\n",
      " - 50s - loss: 0.2677 - acc: 0.8922 - val_loss: 0.3379 - val_acc: 0.8565\n",
      "Epoch 8/10\n",
      " - 49s - loss: 0.2573 - acc: 0.8969 - val_loss: 0.3458 - val_acc: 0.8571\n",
      "Epoch 9/10\n",
      " - 50s - loss: 0.2516 - acc: 0.8979 - val_loss: 0.3671 - val_acc: 0.8539\n",
      "Epoch 10/10\n",
      " - 49s - loss: 0.2422 - acc: 0.9028 - val_loss: 0.3651 - val_acc: 0.8526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25561514d30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(\n",
    "  X_train, # Training data\n",
    "  y_train, # Labels of training data\n",
    "  batch_size=128, # Batch size for the optimizer algorithm\n",
    "  epochs=10, # Number of epochs to run the optimizer algorithm\n",
    "  verbose=2, # Level of verbosity of the log messages\n",
    "  validation_data=(X_test,y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_score=0.8590"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much like other neural layers, LSTM layers can be stacked on top of each other to produce more complex models. Care must be taken, however, that the LSTM layers before the last one generate a whole sequence of outputs for the following LSTM to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n",
    "Repeat the training of the previous network, but using 2 LSTM layers. Make sure to configure the first LSTM layer in a way that it outputs a whole sequence for the next layer.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1, 64,input_length=300))\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18750 samples, validate on 6250 samples\n",
      "Epoch 1/20\n",
      " - 277s - loss: 0.4929 - acc: 0.7537 - val_loss: 0.3903 - val_acc: 0.8274\n",
      "Epoch 2/20\n",
      " - 285s - loss: 0.3411 - acc: 0.8575 - val_loss: 0.3342 - val_acc: 0.8589\n",
      "Epoch 3/20\n",
      " - 286s - loss: 0.3296 - acc: 0.8665 - val_loss: 0.3376 - val_acc: 0.8547\n",
      "Epoch 4/20\n",
      " - 289s - loss: 0.3066 - acc: 0.8746 - val_loss: 0.3493 - val_acc: 0.8538\n",
      "Epoch 5/20\n",
      " - 291s - loss: 0.2907 - acc: 0.8812 - val_loss: 0.3413 - val_acc: 0.8576\n",
      "Epoch 6/20\n",
      " - 293s - loss: 0.2741 - acc: 0.8903 - val_loss: 0.3435 - val_acc: 0.8520\n",
      "Epoch 7/20\n",
      " - 295s - loss: 0.2617 - acc: 0.8941 - val_loss: 0.3672 - val_acc: 0.8530\n",
      "Epoch 8/20\n",
      " - 297s - loss: 0.2529 - acc: 0.8979 - val_loss: 0.3531 - val_acc: 0.8494\n",
      "Epoch 9/20\n",
      " - 297s - loss: 0.2490 - acc: 0.9017 - val_loss: 0.3639 - val_acc: 0.8469\n",
      "Epoch 10/20\n",
      " - 295s - loss: 0.2391 - acc: 0.9041 - val_loss: 0.3815 - val_acc: 0.8490\n",
      "Epoch 11/20\n",
      " - 298s - loss: 0.2263 - acc: 0.9097 - val_loss: 0.4204 - val_acc: 0.8456\n",
      "Epoch 12/20\n",
      " - 299s - loss: 0.2198 - acc: 0.9127 - val_loss: 0.3815 - val_acc: 0.8466\n",
      "Epoch 13/20\n",
      " - 300s - loss: 0.2193 - acc: 0.9135 - val_loss: 0.4046 - val_acc: 0.8435\n",
      "Epoch 14/20\n",
      " - 303s - loss: 0.1973 - acc: 0.9225 - val_loss: 0.4312 - val_acc: 0.8381\n",
      "Epoch 15/20\n",
      " - 305s - loss: 0.1834 - acc: 0.9313 - val_loss: 0.4541 - val_acc: 0.8389\n",
      "Epoch 16/20\n",
      " - 306s - loss: 0.1818 - acc: 0.9300 - val_loss: 0.4526 - val_acc: 0.8277\n",
      "Epoch 17/20\n",
      " - 305s - loss: 0.1617 - acc: 0.9406 - val_loss: 0.4780 - val_acc: 0.8226\n",
      "Epoch 18/20\n",
      " - 308s - loss: 0.1462 - acc: 0.9461 - val_loss: 0.5413 - val_acc: 0.8392\n",
      "Epoch 19/20\n",
      " - 311s - loss: 0.1584 - acc: 0.9401 - val_loss: 0.5257 - val_acc: 0.8339\n",
      "Epoch 20/20\n",
      " - 312s - loss: 0.1378 - acc: 0.9504 - val_loss: 0.5409 - val_acc: 0.8328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x255533c1550>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(\n",
    "  X_train, # Training data\n",
    "  y_train, # Labels of training data\n",
    "  batch_size=128, # Batch size for the optimizer algorithm\n",
    "  epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "  verbose=2, # Level of verbosity of the log messages\n",
    "  validation_data=(X_test,y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_score=0.8589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
